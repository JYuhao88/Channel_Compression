{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch.nn as nn \n",
    "import torch \n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset    \n",
    "import os \n",
    "from tqdm import tqdm\n",
    "import scipy.io as sio\n",
    "from torch.cuda.amp import autocast, GradScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Num2Bit(Num, B):\n",
    "    Num_ = Num.type(torch.uint8)\n",
    "    def integer2bit(integer, num_bits=B * 2):\n",
    "        dtype = integer.type()\n",
    "        exponent_bits = -torch.arange(-(num_bits - 1), 1).type(dtype)\n",
    "        exponent_bits = exponent_bits.repeat(integer.shape + (1,))\n",
    "        out = integer.unsqueeze(-1) // 2 ** exponent_bits\n",
    "        return (out - (out % 1)) % 2\n",
    "    bit = integer2bit(Num_)\n",
    "    bit = (bit[:, :, B:]).reshape(-1, Num_.shape[1] * B)\n",
    "    return bit.type(torch.float32)\n",
    "def Bit2Num(Bit, B):\n",
    "    Bit_ = Bit.type(torch.float32)\n",
    "    Bit_ = torch.reshape(Bit_, [-1, int(Bit_.shape[1] / B), B])\n",
    "    num = torch.zeros(Bit_[:, :, 1].shape).cuda()\n",
    "    for i in range(B):\n",
    "        num = num + Bit_[:, :, i] * 2 ** (B - 1 - i)\n",
    "    return num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Quantization(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, x, B):\n",
    "        ctx.constant = B\n",
    "        step = 2 ** B\n",
    "        out = torch.round(x * step - 0.5)\n",
    "        out = Num2Bit(out, B)\n",
    "        return out\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        # return as many input gradients as there were arguments.\n",
    "        # Gradients of constant arguments to forward must be None.\n",
    "        # Gradient of a number is the sum of its B bits.\n",
    "        b, _ = grad_output.shape\n",
    "        grad_num = torch.sum(grad_output.reshape(b, -1, ctx.constant), dim=2) / ctx.constant\n",
    "        return grad_num, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dequantization(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, x, B):\n",
    "        ctx.constant = B\n",
    "        step = 2 ** B\n",
    "        out = Bit2Num(x, B)\n",
    "        out = (out + 0.5) / step\n",
    "        return out\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        # return as many input gradients as there were arguments.\n",
    "        # Gradients of non-Tensor arguments to forward must be None.\n",
    "        # repeat the gradient of a Num for B time.\n",
    "        b, c = grad_output.shape\n",
    "        grad_output = grad_output.unsqueeze(2) / ctx.constant\n",
    "        grad_bit = grad_output.expand(b, c, ctx.constant)\n",
    "        return torch.reshape(grad_bit, (-1, c * ctx.constant)), None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuantizationLayer(nn.Module):\n",
    "    def __init__(self, B):\n",
    "        super(QuantizationLayer, self).__init__()\n",
    "        self.B = B\n",
    "    def forward(self, x):\n",
    "        out = Quantization.apply(x, self.B)\n",
    "        return out\n",
    "class DequantizationLayer(nn.Module):\n",
    "    def __init__(self, B):\n",
    "        super(DequantizationLayer, self).__init__()\n",
    "        self.B = B\n",
    "    def forward(self, x):\n",
    "        out = Dequantization.apply(x, self.B)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv3x3(in_planes, out_planes, stride=1):\n",
    "    \"\"\"3x3 convolution with padding\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                     padding=1, bias=True)\n",
    "\n",
    "def conv1x1(in_planes, out_planes, stride=1):\n",
    "    \"\"\"1x1 convolution with no padding\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride,\n",
    "                     padding=0, bias=True)\n",
    "\n",
    "def conv2x2(in_planes, out_planes, stride=1):\n",
    "    \"\"\"2x2 convolution with padding\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=2, stride=stride,\n",
    "                     padding=1, bias=True)\n",
    "def conv5x5(in_planes, out_planes, stride=1):\n",
    "    \"\"\"5x5 convolution with  no padding\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=5, stride=stride,\n",
    "                     padding=0, bias=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SE_module(nn.Module):\n",
    "    def __init__(self, channel, r):\n",
    "        super(SE_module, self).__init__()\n",
    "        self.__avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.__fc = nn.Sequential(\n",
    "            nn.Conv2d(channel, channel//r, 1, bias=False),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(channel//r, channel, 1, bias=False),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        y = self.__avg_pool(x)\n",
    "        y = self.__fc(y)\n",
    "        return x * y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Channel_Attention(nn.Module):\n",
    "    def __init__(self, channel, r):\n",
    "        super(Channel_Attention, self).__init__()\n",
    "        self.__avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.__max_pool = nn.AdaptiveMaxPool2d((1, 1))\n",
    "\n",
    "        self.__fc = nn.Sequential(\n",
    "            nn.Conv2d(channel, channel//r, 1, bias=False),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(channel//r, channel, 1, bias=False),\n",
    "        )\n",
    "        self.__sigmoid = nn.Sigmoid()\n",
    "    def forward(self, x):\n",
    "        y1 = self.__avg_pool(x)\n",
    "        y1 = self.__fc(y1)\n",
    "\n",
    "        y2 = self.__max_pool(x)\n",
    "        y2 = self.__fc(y2)\n",
    "\n",
    "        y = self.__sigmoid(y1+y2)\n",
    "        return x * y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Spartial_Attention(nn.Module):\n",
    "    def __init__(self, kernel_size):\n",
    "        super(Spartial_Attention, self).__init__()\n",
    "\n",
    "        assert kernel_size % 2 == 1, \"kernel_size = {}\".format(kernel_size)\n",
    "        padding = (kernel_size - 1) // 2\n",
    "\n",
    "        self.__layer = nn.Sequential(\n",
    "            nn.Conv2d(2, 1, kernel_size=kernel_size, padding=padding),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        avg_mask = torch.mean(x, dim=1, keepdim=True)\n",
    "        max_mask, _ = torch.max(x, dim=1, keepdim=True)\n",
    "        mask = torch.cat([avg_mask, max_mask], dim=1)\n",
    "\n",
    "        mask = self.__layer(mask)\n",
    "        return x * mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionRefineNet(nn.Module):\n",
    "    def __init__(self, channel):\n",
    "        super(AttentionRefineNet, self).__init__()\n",
    "        self.multiAtt = nn.Sequential(\n",
    "            conv3x3(2, 16),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.LeakyReLU(0.3),\n",
    "            Channel_Attention(16, 1),\n",
    "            conv3x3(16, 8),\n",
    "            nn.BatchNorm2d(8),\n",
    "            nn.LeakyReLU(0.3),\n",
    "            Channel_Attention(8, 1),\n",
    "            conv3x3(8, 2),\n",
    "            nn.BatchNorm2d(2)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        residual = self.multiAtt(x)\n",
    "        return x+residual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    num_quan_bits = 4\n",
    "    def __init__(self,feedback_bits):\n",
    "        super(Encoder,self).__init__()\n",
    "        self.conv1 = conv3x3(3,3)\n",
    "        self.conv2 = conv3x3(3,3)\n",
    "        self.fc = nn.Linear(768,int(feedback_bits/num_quan_bits))\n",
    "        self.sig = nn.Sigmoid()\n",
    "        self.quantize = QuantizationLayer(self.num_quan_bits)\n",
    "    def forward(self,x):\n",
    "        x = x.permute(0,3,1,2)\n",
    "        out = F.relu(self.conv1(x))\n",
    "        out = F.relu(self.conv2(x))\n",
    "        out = out.contiguous().view(-1,768)\n",
    "        out = self.fc(out)\n",
    "        out = self.sig(out)\n",
    "        out = self.quantize(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "##attention机制\n",
    "class Decoder(nn.Module):\n",
    "    num_quan_bits = 4\n",
    "    def __init__(self, feedback_bits):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.feedback_bits = feedback_bits\n",
    "        self.dequantize = DequantizationLayer(self.num_quan_bits)\n",
    "        self.fc = nn.Linear(int(feedback_bits / self.num_quan_bits), 768)\n",
    "        self.sig = nn.Sigmoid()\n",
    "        self.AttentionNet = nn.Sequential(\n",
    "                AttentionRefineNet(2),\n",
    "                nn.LeakyReLU(0.3),\n",
    "                AttentionRefineNet(2),\n",
    "                conv3x3(2, 2),\n",
    "                nn.BatchNorm2d(2),\n",
    "                nn.Sigmoid())\n",
    "    def forward(self, x):\n",
    "        out = self.dequantize(x)\n",
    "        out = out.contiguous().view(-1, int(self.feedback_bits / self.num_quan_bits)) #需使用contiguous().view(),或者可修改为reshape\n",
    "        out = self.sig(self.fc(out))\n",
    "        out = out.contiguous().view(-1, 2, 24, 16) #需使用contiguous().view(),或者可修改为reshape\n",
    "        out = self.AttentionNet(out)\n",
    "        \n",
    "        out = out.permute(0, 2, 3, 1)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##baseline \n",
    "class Decoder(nn.Module):\n",
    "    num_quan_bits = 4\n",
    "    def __init__(self, feedback_bits):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.feedback_bits = feedback_bits\n",
    "        self.dequantize = DequantizationLayer(self.num_quan_bits)\n",
    "        self.multiConvs = nn.ModuleList()\n",
    "        self.fc = nn.Linear(int(feedback_bits / self.num_quan_bits), 768)\n",
    "        self.out_cov = conv3x3(2, 2)\n",
    "        self.sig = nn.Sigmoid()\n",
    "        for _ in range(3):\n",
    "            self.multiConvs.append(nn.Sequential(\n",
    "                conv3x3(2, 8),\n",
    "                nn.ReLU(),\n",
    "                conv3x3(8, 16),\n",
    "                nn.ReLU(),\n",
    "                conv3x3(16, 2),\n",
    "                nn.ReLU()))\n",
    "    def forward(self, x):\n",
    "        out = self.dequantize(x)\n",
    "        out = out.contiguous().view(-1, int(self.feedback_bits / self.num_quan_bits)) #需使用contiguous().view(),或者可修改为reshape\n",
    "        out = self.sig(self.fc(out))\n",
    "        out = out.contiguous().view(-1, 2, 24, 16) #需使用contiguous().view(),或者可修改为reshape\n",
    "        for i in range(3):\n",
    "            residual = out\n",
    "            out = self.multiConvs[i](out)\n",
    "            out = residual + out\n",
    "        out = self.out_cov(out)\n",
    "        out = self.sig(out)\n",
    "        out = out.permute(0, 2, 3, 1)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self,feedback_bits):\n",
    "        super(AutoEncoder,self).__init__()\n",
    "        self.encoder = Encoder(feedback_bits)\n",
    "        self.decoder = Decoder(feedback_bits)\n",
    "    def forward(self,x):\n",
    "        feature = self.encoder(x)\n",
    "        out = self.decoder(feature)\n",
    "        return out "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NMSE(x, x_hat):\n",
    "    x_real = np.reshape(x[:, :, :, 0], (len(x), -1))\n",
    "    x_imag = np.reshape(x[:, :, :, 1], (len(x), -1))\n",
    "    x_hat_real = np.reshape(x_hat[:, :, :, 0], (len(x_hat), -1))\n",
    "    x_hat_imag = np.reshape(x_hat[:, :, :, 1], (len(x_hat), -1))\n",
    "    x_C = x_real - 0.5 + 1j * (x_imag - 0.5)\n",
    "    x_hat_C = x_hat_real - 0.5 + 1j * (x_hat_imag - 0.5)\n",
    "    power = np.sum(abs(x_C) ** 2, axis=1)\n",
    "    mse = np.sum(abs(x_C - x_hat_C) ** 2, axis=1)\n",
    "    nmse = np.mean(mse / power)\n",
    "    return nmse\n",
    "def Score(NMSE):\n",
    "    score = 1 - NMSE\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetFolder(Dataset):\n",
    "    def __init__(self, matData):\n",
    "        self.matdata = matData\n",
    "    def __getitem__(self, index):\n",
    "        return self.matdata[index]\n",
    "    def __len__(self):\n",
    "        return self.matdata.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batch_size = 512\n",
    "test_batch_size= 512\n",
    "epochs = 10\n",
    "num_feedback_bit=384\n",
    "num_quan_bits = 4\n",
    "learning_rate = 1e-3\n",
    "print_freq = 50 \n",
    "img_height = 16\n",
    "img_width = 24\n",
    "img_channels = 2\n",
    "torch.manual_seed(10)\n",
    "np.random.seed(11)\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0,1'\n",
    "use_single_gpu = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat = sio.loadmat('H_4T4R.mat') \n",
    "data = mat['H_4T4R']\n",
    "data = data.astype('float32')\n",
    "data = np.reshape(data,(len(data),img_width,img_height,img_channels))\n",
    "split = int(data.shape[0]*0.7)\n",
    "data_train,data_test = data[:split],data[split:]\n",
    "train_dataset = DatasetFolder(data_train)\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset,batch_size=train_batch_size,shuffle=True,\n",
    "                                              num_workers=0,pin_memory=True)\n",
    "test_dataset = DatasetFolder(data_test)\n",
    "test_dataloadder = torch.utils.data.DataLoader(test_dataset,batch_size=test_barch_size,shuffle=False,\n",
    "                                              num_workers=0,pin_memory=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoderModel = AutoEncoder(num_feedback_bit)\n",
    "autoencoderModel = autoencoderModel.cuda()\n",
    "criterion = nn.MSELoss().cuda()\n",
    "optimizer = torch.optim.Adam(autoencoderModel.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_single_gpu:\n",
    "    autoencoderModel = autoencoderModel.cuda()\n",
    "else:\n",
    "    autoencoderModel = autoencoderModel.cuda()\n",
    "    autoencoderModel = torch.nn.DataParallel(autoencoderModel,device_ids=[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Caught RuntimeError in replica 0 on device 0.\nOriginal Traceback (most recent call last):\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\parallel\\parallel_apply.py\", line 61, in _worker\n    output = module(*input, **kwargs)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 727, in _call_impl\n    result = self.forward(*input, **kwargs)\n  File \"<ipython-input-13-b3e372d41e63>\", line 7, in forward\n    feature = self.encoder(x)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 727, in _call_impl\n    result = self.forward(*input, **kwargs)\n  File \"<ipython-input-11-e0a0e38e20f2>\", line 12, in forward\n    out = F.relu(self.conv1(x))\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 727, in _call_impl\n    result = self.forward(*input, **kwargs)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\conv.py\", line 423, in forward\n    return self._conv_forward(input, self.weight)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\conv.py\", line 419, in _conv_forward\n    return F.conv2d(input, weight, self.bias, self.stride,\nRuntimeError: Given groups=1, weight of size [3, 3, 3, 3], expected input[256, 2, 24, 16] to have 3 channels, but got 2 channels instead\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-6b7390ec2469>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mautocast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m             \u001b[0mautoencoderOutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mautoencoderModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mautoencoderInput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mautoencoderOutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mautoencoderInput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\parallel\\data_parallel.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[0;32m    159\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    160\u001b[0m         \u001b[0mreplicas\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplicate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 161\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparallel_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    162\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput_device\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    163\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\parallel\\data_parallel.py\u001b[0m in \u001b[0;36mparallel_apply\u001b[1;34m(self, replicas, inputs, kwargs)\u001b[0m\n\u001b[0;32m    169\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    170\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mparallel_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreplicas\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 171\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mparallel_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    172\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    173\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mgather\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_device\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\parallel\\parallel_apply.py\u001b[0m in \u001b[0;36mparallel_apply\u001b[1;34m(modules, inputs, kwargs_tup, devices)\u001b[0m\n\u001b[0;32m     84\u001b[0m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 86\u001b[1;33m             \u001b[0moutput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     87\u001b[0m         \u001b[0moutputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\_utils.py\u001b[0m in \u001b[0;36mreraise\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    426\u001b[0m             \u001b[1;31m# have message field\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    427\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 428\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    429\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    430\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Caught RuntimeError in replica 0 on device 0.\nOriginal Traceback (most recent call last):\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\parallel\\parallel_apply.py\", line 61, in _worker\n    output = module(*input, **kwargs)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 727, in _call_impl\n    result = self.forward(*input, **kwargs)\n  File \"<ipython-input-13-b3e372d41e63>\", line 7, in forward\n    feature = self.encoder(x)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 727, in _call_impl\n    result = self.forward(*input, **kwargs)\n  File \"<ipython-input-11-e0a0e38e20f2>\", line 12, in forward\n    out = F.relu(self.conv1(x))\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 727, in _call_impl\n    result = self.forward(*input, **kwargs)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\conv.py\", line 423, in forward\n    return self._conv_forward(input, self.weight)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\conv.py\", line 419, in _conv_forward\n    return F.conv2d(input, weight, self.bias, self.stride,\nRuntimeError: Given groups=1, weight of size [3, 3, 3, 3], expected input[256, 2, 24, 16] to have 3 channels, but got 2 channels instead\n"
     ]
    }
   ],
   "source": [
    "bestLoss = 1\n",
    "scaler = GradScaler()\n",
    "for epoch in range(epochs):\n",
    "    autoencoderModel.train()\n",
    "    for i, autoencoderInput in enumerate(train_dataloader):\n",
    "        autoencoderInput = autoencoderInput.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        with autocast():\n",
    "            autoencoderOutput = autoencoderModel(autoencoderInput)\n",
    "            loss = criterion(autoencoderOutput, autoencoderInput)\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        NMSE_=NMSE(autoencoderInput.cpu().detach().numpy(),autoencoderOutput.cpu().detach().numpy())\n",
    "        if i % print_freq == 0:\n",
    "            print('Epoch: [{0}][{1}/{2}]\\t' 'Loss {loss:.4f}\\t''NMSE{NMSE:.4f}\\t'.format(epoch, i, len(train_loader), loss=loss.item(),NMSE=NMSE_))\n",
    "    autoencoderModel.eval()\n",
    "    totalLoss = 0\n",
    "    with torch.no_grad():\n",
    "        for i, autoencoderInput in enumerate(test_dataloadder):\n",
    "            autoencoderInput = autoencoderInput.cuda()\n",
    "            autoencoderOutput = autoencoderModel(autoencoderInput)\n",
    "            totalLoss += criterion(autoencoderOutput, autoencoderInput).item() * autoencoderInput.size(0)\n",
    "        averageLoss = totalLoss / len(test_dataset)\n",
    "        if averageLoss < bestLoss:\n",
    "            torch.save({'state_dict': autoencoderModel.encoder.state_dict(), }, 'modelSubmit/encoder.pth.tar')\n",
    "            torch.save({'state_dict': autoencoderModel.decoder.state_dict(), }, 'modelSubmit/decoder.pth.tar')\n",
    "            print(\"Model saved\")\n",
    "            bestLoss = averageLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_dataloader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-9afdb03de67b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mdel\u001b[0m \u001b[0mautoencoderModel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest_dataloader\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'test_dataloader' is not defined"
     ]
    }
   ],
   "source": [
    " del autoencoderModel, optimizer, train_dataloader,test_dataloader\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    for i, test_input in enumerate(test_dataloader):\n",
    "        test_input = test_put.cuda()\n",
    "        test_out = autoencoderModel(test_input)\n",
    "        test_out = test_out.cpu().numpy()\n",
    "        if i == 0:\n",
    "            H_pre = test_out\n",
    "        else:\n",
    "            H_pre = np.concatenate((H_pre, test_out), axis=0)\n",
    "H_test = data_test\n",
    "print(NMSE(H_test, H_pre))\n",
    "if (NMSE(H_test, H_pre) < 0.1):\n",
    "    print('Valid Submission')\n",
    "    print('The Score is ' + np.str(1.0 - NMSE(H_test, H_pre)))\n",
    "print('Finished!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
